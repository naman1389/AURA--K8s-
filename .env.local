# =============================================================================
# AURA K8s - Local Development Environment Configuration
# =============================================================================
# HYBRID SETUP: Application services run LOCALLY, infrastructure in Docker
#
# Running LOCALLY on your machine:
# - Collector (Go) - localhost:9090
# - Remediator (Go) - localhost:9091
# - ML Service (Python) - localhost:8001
# - MCP Server (Python) - localhost:8000
# - Orchestrator scripts (Python)
#
# Running in DOCKER:
# - TimescaleDB - localhost:5432 (port mapped from container)
# - Kind cluster (Kubernetes) - via kubeconfig
# - Grafana (optional) - localhost:3000 (if you want it in Docker)
# =============================================================================

# -----------------------------------------------------------------------------
# Environment Detection
# -----------------------------------------------------------------------------
ENVIRONMENT=development

# -----------------------------------------------------------------------------
# Database Configuration (TimescaleDB in Docker)
# -----------------------------------------------------------------------------
# TimescaleDB runs in Docker but accessible via localhost:5432 (port mapping)
DATABASE_URL=postgresql://aura:aura_password@localhost:5432/aura_metrics?sslmode=disable

# Component-based (uses localhost since Docker maps port)
POSTGRES_USER=aura
POSTGRES_PASSWORD=aura_password
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=aura_metrics

# TimescaleDB specific
TIMESCALEDB_ENABLED=true
SKIP_SCHEMA_INIT=false

# Database Connection Pool Settings
MAX_DB_OPEN_CONNS=25
MAX_DB_IDLE_CONNS=5
DB_CONN_MAX_LIFETIME=30m
DB_CONN_MAX_IDLE_TIME=5m

# -----------------------------------------------------------------------------
# Service Ports (Local Services)
# -----------------------------------------------------------------------------
COLLECTOR_PORT=9090
REMEDIATOR_PORT=9091
ML_SERVICE_PORT=8001
MCP_SERVER_PORT=8000
GRAFANA_PORT=3000

# -----------------------------------------------------------------------------
# Service URLs (All Local Services Use localhost)
# -----------------------------------------------------------------------------
# All application services run locally, so all use localhost
ML_SERVICE_URL=http://localhost:8001
MCP_SERVER_URL=http://localhost:8000
COLLECTOR_URL=http://localhost:9090
REMEDIATOR_URL=http://localhost:9091
GRAFANA_URL=http://localhost:3000

# Service Hosts (explicit localhost for local services)
ML_SERVICE_HOST=localhost
MCP_SERVER_HOST=localhost
COLLECTOR_HOST=localhost
REMEDIATOR_HOST=localhost
GRAFANA_HOST=localhost

# -----------------------------------------------------------------------------
# Kubernetes Configuration (Kind Cluster in Docker)
# -----------------------------------------------------------------------------
KUBECONFIG=~/.kube/config
K8S_NAMESPACE=aura-system

# Kubernetes API settings (for connecting to Kind cluster)
K8S_QPS=50
K8S_BURST=100
K8S_TIMEOUT_SECONDS=30

# -----------------------------------------------------------------------------
# Collection Settings
# -----------------------------------------------------------------------------
COLLECTION_INTERVAL=15s
USE_PARALLEL_COLLECTION=true
METRICS_COLLECTOR_WORKERS=20
METRICS_COLLECTOR_BATCH_SIZE=100
METRICS_CACHE_TTL_SECONDS=10

# Metrics Port
METRICS_PORT=9090

# -----------------------------------------------------------------------------
# ML Service Configuration (Local)
# -----------------------------------------------------------------------------
MODEL_PATH=./ml/train/models
CONFIDENCE_THRESHOLD=0.50
ML_TIMEOUT=10s

# -----------------------------------------------------------------------------
# MCP Server Configuration (Local)
# -----------------------------------------------------------------------------
# MCP Server runs locally on localhost:8000

# -----------------------------------------------------------------------------
# Ollama Configuration
# -----------------------------------------------------------------------------
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# -----------------------------------------------------------------------------
# Grafana Configuration
# -----------------------------------------------------------------------------
# Grafana can run locally or in Docker - both accessible via localhost:3000
GRAFANA_USER=admin
GRAFANA_PASSWORD=admin
GRAFANA_ROOT_URL=http://localhost:3000

# -----------------------------------------------------------------------------
# Logging Configuration
# -----------------------------------------------------------------------------
LOG_LEVEL=info
LOG_DIR=./logs
LOG_MAX_SIZE_MB=100
LOG_MAX_AGE_DAYS=7
LOG_MAX_BACKUPS=5
LOG_COMPRESS=true

# -----------------------------------------------------------------------------
# Remediation Settings
# -----------------------------------------------------------------------------
REMEDIATION_INTERVAL=30s
PREVENTIVE_REMEDIATION_INTERVAL=10s
REMEDIATION_DELAY_SECONDS=2
REMEDIATION_ACTION_DELAY_SECONDS=3
REMEDIATION_RISK_LEVEL=medium
DRY_RUN=false

# -----------------------------------------------------------------------------
# Prediction & Forecasting Settings
# -----------------------------------------------------------------------------
PREDICTION_INTERVAL=30
FORECAST_INTERVAL=5
PREDICTION_HORIZON=900
ENABLE_PREVENTIVE_ACTIONS=true

# -----------------------------------------------------------------------------
# Thresholds (CPU, Memory, Confidence)
# -----------------------------------------------------------------------------
HIGH_CPU_THRESHOLD=80.0
HIGH_MEMORY_THRESHOLD=80.0
MIN_CONFIDENCE_FOR_REMEDIATION=0.5
HIGH_CONFIDENCE_THRESHOLD=0.8
MEDIUM_CONFIDENCE_THRESHOLD=0.6

# -----------------------------------------------------------------------------
# Retry Configuration
# -----------------------------------------------------------------------------
MAX_RETRIES=3
RETRY_BACKOFF_MS=500
DEFAULT_REQUEST_TIMEOUT=90s
DEFAULT_SHUTDOWN_TIMEOUT=30s

# -----------------------------------------------------------------------------
# Timeout Values
# -----------------------------------------------------------------------------
DEFAULT_K8S_TIMEOUT=30s
DEFAULT_MCP_TIMEOUT=90s
DEFAULT_ML_TIMEOUT=10s
DEFAULT_HEALTH_TIMEOUT=5s

# -----------------------------------------------------------------------------
# Circuit Breaker Settings
# -----------------------------------------------------------------------------
CIRCUIT_BREAKER_FAILURE_THRESHOLD=5
CIRCUIT_BREAKER_RESET_TIMEOUT=60s

# -----------------------------------------------------------------------------
# Batch Processing
# -----------------------------------------------------------------------------
DEFAULT_BATCH_SIZE=20

# -----------------------------------------------------------------------------
# Resource Management
# -----------------------------------------------------------------------------
DEFAULT_RESOURCE_REQUEST_RATIO=0.8

# -----------------------------------------------------------------------------
# Cost Calculation
# -----------------------------------------------------------------------------
CPU_COST_PER_CORE_PER_HOUR=0.10
MEMORY_COST_PER_GB_PER_HOUR=0.05

# -----------------------------------------------------------------------------
# Performance Tuning
# -----------------------------------------------------------------------------
GOMAXPROCS=0
GOGC=100
ENABLE_PPROF=true
PPROF_ADDR=localhost:6060

# -----------------------------------------------------------------------------
# API Keys & Secrets
# -----------------------------------------------------------------------------
GEMINI_API_KEY=AIzaSyAsjBOHLd_w3TYOU6gZzSkAlXXraqQxk1U

# -----------------------------------------------------------------------------
# Circular Buffer Settings
# -----------------------------------------------------------------------------
USE_CIRCULAR_BUFFER=true

# -----------------------------------------------------------------------------
# Required Ports
# -----------------------------------------------------------------------------
REQUIRED_PORTS=5432,8000,8001,9090,9091,3000,11434

# =============================================================================
# SETUP INSTRUCTIONS FOR LOCAL DEVELOPMENT
# =============================================================================
#
# 1. Start Docker infrastructure:
#    docker-compose up -d timescaledb
#    # Optional: docker-compose up -d grafana
#
# 2. Start Kind cluster (if not already running):
#    kind create cluster --name aura
#    # Or use existing: kubectl config use-context kind-aura
#
# 3. Verify TimescaleDB:
#    psql -h localhost -U aura -d aura_metrics
#    # Or: docker exec -it aura-timescaledb psql -U aura -d aura_metrics
#
# 4. Start local services (in separate terminals):
#    # Terminal 1 - Collector
#    go run cmd/collector/main.go
#
#    # Terminal 2 - Remediator
#    go run cmd/remediator/main.go
#
#    # Terminal 3 - ML Service (if you have one)
#    python scripts/ml_service.py
#
#    # Terminal 4 - MCP Server
#    python mcp/server_ollama.py
#
#    # Terminal 5 - Orchestrator
#    python scripts/orchestrator.py
#
# 5. Verify services:
#    curl http://localhost:9090/health  # Collector
#    curl http://localhost:9091/health  # Remediator
#    curl http://localhost:8001/health  # ML Service
#    curl http://localhost:8000/health  # MCP Server
#
# 6. Access Grafana (if running):
#    http://localhost:3000 (admin/admin)
#
# =============================================================================
